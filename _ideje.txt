- ko change point detection zazna spremembo se stanje nekako resetira:
	*tisti bandit B, ki je sprožil reset se nastavi na število vzorcev N kolikor jih je bilo v moving average
	*ostale bandite pa je potrebno resetirat na drugaèno število - potrebno je gledat ne absolutno po številu potegov, ampak po èasu (koliko potegov je bilo vsakega bandita od toèke v preteklosti, ko je moving average naredil N vozrcev bandita B)
		-- preizkusi obe opciji (z in brez tega)

- exploration parameter (C, epsilon, ...) linearna funkcija naslednjih spremenljivk:
	*število avtomatov/akcij/banditov
	*število vseh potegov (max_pulls), se spremeni z resetom
	*trenutno število potegov (tako lahko funkcija se linearno zmanjšuje od zaèetka do konca, na primer)
	*število potegov od zadnjega reseta zaradi changePointDetection ... ta je lahko posebej ali tudi enaka zgornji, da se izognemo še enemu parametru

- poskusi ensamble of algorithms
	*glede na izmerjene rezulate po posameznih primerih ugotovi ali se splaèa sploh uporabit kaj drugega kot UCB1tuned
	*èe ja, potem naredi nek "voting system" na primer treh algoritmov, kjer se izbere tisti machine/akcija, ki ima najveè glasov, sicer pa èe imajo vsi enako naj prevlada npr. UCB1tuned
	
- (lahko je popolnoma mimo...) v primeru, ko imaš ogromno nièel in le nekaj enic, smatraš, da ti stroj vraèa povpreèno vrednost vseh preteklih rewardov (delaš dejansko prediction), ali je to smiselno ?? kaj bi se zgodilo?